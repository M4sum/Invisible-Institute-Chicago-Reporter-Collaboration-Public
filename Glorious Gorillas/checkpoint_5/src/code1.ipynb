{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADER: Update the current_directory below to whichever directory you are loading this file from to be able to load the proper CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ilanponsky/Desktop/checkpoint_5/src'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\"\"\"\n",
    "GRADER: Update the current_directory below to whichever directory \n",
    "you are loading this file from to be able to load the proper CSV files.\n",
    "\n",
    "This should be the directory to get to checkpoint_5\n",
    "\"\"\"\n",
    "\n",
    "# Update HERE\n",
    "current_directory = '/.../checkpoint_5/src'\n",
    "\n",
    "os.chdir(current_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load CSV files (data and labels)\n",
    "data = pd.read_csv(\"cpdb_public_checkpoint5.csv\") \n",
    "data = data.dropna()\n",
    "\n",
    "officer_ranking_list = pd.read_csv('cpdb_public_officer_rank_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = np.array(data)\n",
    "officer_ranking_list = np.array(officer_ranking_list)\n",
    "or_list = []\n",
    "\n",
    "for rank in officer_ranking_list:\n",
    "    or_list.append(rank[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings to \"Numerify\" the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Lieutenant'), (1, 'Assistant Superintendent'), (2, 'Sergeant'), (3, 'Commander'), (4, 'Police Officer'), (5, 'Detective'), (6, 'Superintendent Of Police'), (7, 'Other'), (8, 'Deputy Chief'), (9, 'Director Of Caps'), (10, 'Chief'), (11, \"Superintendent'S Chief Of Staff\"), (12, 'Captain'), (13, 'Field Training Officer'), (14, 'Deputy Superintendent'), (15, 'First Deputy Superintendent'), (16, 'Assistant Deputy Superintendent')]\n"
     ]
    }
   ],
   "source": [
    "victim_race_labs = [\n",
    "    (0, 'Asian/Pacific Islander'),\n",
    "    (1, 'Hispanic'),\n",
    "    (2, 'White'),\n",
    "    (3, 'Native American/Alaskan Native'),\n",
    "    (4, 'Black')\n",
    "]\n",
    "\n",
    "officer_race_labs = [\n",
    "    (0, 'Asian/Pacific'),\n",
    "    (1, 'Hispanic'),\n",
    "    (2, 'White'),\n",
    "    (3, 'Native American/Alaskan Native'),\n",
    "    (4, 'Black')\n",
    "]\n",
    "\n",
    "or_list = []\n",
    "for i, rank in enumerate(officer_ranking_list):\n",
    "    or_list.append((i, rank[0]))\n",
    "    \n",
    "or_list.append((16, 'Assistant Deputy Superintendent'))\n",
    "print(or_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is a function to Numerify data to convert all data to float values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Strings to numerical values based on mapping above\n",
    "\n",
    "def numerify(data):\n",
    "    new_data = []\n",
    "    for i, row in enumerate(data):\n",
    "        temp = row\n",
    "        \n",
    "        # Victim Race\n",
    "        race = temp[2]\n",
    "        for j in victim_race_labs:\n",
    "            if race == j[1]:\n",
    "                temp[2] = j[0]\n",
    "        \n",
    "        # Officer Race\n",
    "        o_race = temp[4]\n",
    "        for j in officer_race_labs:\n",
    "            if o_race == j[1]:\n",
    "                temp[4] = j[0]\n",
    "        \n",
    "        # Officer Rank\n",
    "        rank = temp[5]\n",
    "        for j in or_list:\n",
    "            if rank == j[1]:\n",
    "                temp[5] = j[0]\n",
    "                \n",
    "        temp = temp.tolist()\n",
    "        new_data.append(temp)\n",
    "    \n",
    "    new_data = np.array(new_data, dtype=float)\n",
    "    new_data = new_data[:, 1:]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Numerify\n",
    "num_data = numerify(data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are the machine learning models we ran on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 analysis using an SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Full feature set, targets are counts of allegations per officer\n",
    "\n",
    "features = num_data[:, 0:-1]\n",
    "targets = num_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2)\n",
    "\n",
    "# Run Model\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of allegations predictions: \n",
      " [2. 3. 4. 6. 1. 3. 6. 4. 1. 2. 2. 2. 2. 1. 6. 2. 2. 2. 6. 2.]\n"
     ]
    }
   ],
   "source": [
    "print('Number of allegations predictions: \\n', predictions1[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for predicting amount of allegations per officer:\n",
      "---------------------------------------------------------\n",
      "F1 score:\t 0.9525559658566799\n",
      "Accuracy Score:  0.9365466748017084\n"
     ]
    }
   ],
   "source": [
    "print('Results for predicting amount of allegations per officer:')\n",
    "print('---------------------------------------------------------')\n",
    "f1 = f1_score(predictions1, y_test, average='weighted')\n",
    "print('F1 score:\\t', f1)\n",
    "\n",
    "accuracy = accuracy_score(predictions1, y_test)\n",
    "print('Accuracy Score: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 analysis using an SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full feature set, targets are most commonly targeted racial group per officer\n",
    "\n",
    "features = np.delete(num_data, 1, axis=1)\n",
    "targets = num_data[:, 1]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2)\n",
    "\n",
    "# Run Model\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions2 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for most commonly targeted racial group predictions: \n",
      " [4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "print('Label for most commonly targeted racial group predictions: \\n', predictions2[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for predicting most commonly targeted racial group per officer:\n",
      "-----------------------------------------------------------------------\n",
      "F1 score:\t 0.7750373692077728\n",
      "Accuracy Score:  0.6327028676021964\n"
     ]
    }
   ],
   "source": [
    "print('Results for predicting most commonly targeted racial group per officer:')\n",
    "print('-----------------------------------------------------------------------')\n",
    "f1 = f1_score(predictions2, y_test, average='weighted')\n",
    "print('F1 score:\\t', f1)\n",
    "\n",
    "accuracy = accuracy_score(predictions2, y_test)\n",
    "print('Accuracy Score: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
